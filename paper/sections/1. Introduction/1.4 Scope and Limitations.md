## 1.4 Scope and Limitations

### 1.4.1 Scope of the Study
This study focuses on developing a chatbot prototype that answers inquiries specifically about Japan visa requirements in English, using data gathered from a travel agency branch in Quezon City that actively handles such inquiries, primarily through Facebook Messenger. The chatbot will be integrated exclusively within Messenger, where most client interactions occur. The data sources for training the chatbot include:

- Frequently asked client inquiries provided by the travel agency, based on real-world questions they commonly receive about Japan visa requirements. This includes non-public knowledge the agency has acquired over time from handling various visa applications.

- Official documentation from the Japan Embassy in the Philippines website, particularly from the Visa/Consular Services section, where downloadable PDFs outline the general visa requirements.

The travel agency has granted permission to access past conversation history for research purposes, and all personally identifiable information (PII) will be removed to comply with the Data Privacy Act of 2012 (RA 10173). Although conversations may occur in English, Tagalog, or Cebuano, the study will focus exclusively on English-language interactions. The chatbot will be limited to addressing document-related inquiries concerning Japan visa applications and will serve as a foundational prototype for enhancing customer service in the travel agency sector.

### 1.4.2 Limitations of the Study

This study has several limitations due to practical, technical, and resource-related constraints:

- The deployment of the chatbot will be limited to free-tier hosting using the Google Cloud Platform, which supports Python-based web applications. This approach enables a faster and more cost-effective development process by avoiding the need to build infrastructure from scratch.

- The Large Language Model (LLM) used for generating responses will be GPT-4.0-mini via the OpenAI API. This model is chosen for its balance between cost-efficiency and performance in delivering high-quality responses in the chatbot.

- The embedding model used for document retrieval in the RAG pipeline is OpenAIâ€™s text-embedding-3-large, selected for its strong semantic understanding, which helps improve the relevance of matched visa-related documents and user inquiries.

- To handle query simplification before retrieval, the study will fine-tune a pretrained T5-small model, which is lightweight and well-suited for environments with limited CPU and memory resources. This model was chosen because it offers acceptable performance while remaining resource-efficient for the computing limitations available to the researchers.

These limitations constrain the scalability and computational intensity of the solution but demonstrate the feasibility of implementing a specialized, intelligent chatbot using accessible and cost-effective technologies.