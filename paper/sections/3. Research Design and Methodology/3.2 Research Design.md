## 3.2 Research Design

### Research Approach

This study adopts an **applied research approach** focused on developing and evaluating a prototype RAG-based chatbot for Japan visa support. Applied research emphasizes practical problem-solving through technological innovation (Saunders, Lewis, & Thornhill, 2019). The design is both **developmental** (system construction) and **experimental** (evaluation under real-world constraints), combining system-level and user-level assessments to ensure technical robustness and practical value.

### System Implementation (RAG Workflow)

The chatbot architecture follows a modular RAG pipeline deployed via Facebook Messenger, chosen for its wide adoption in the Philippines. The workflow (Figure X) consists of:

1. **Input Layer**

   * Queries submitted via Messenger are routed through the Meta Webhook to a FastAPI backend.
   * The FastAPI server hosts the RAG logic, including classification, retrieval, and generation.

2. **Binary Classifier**

   * Determines whether a query is Japan visa–related.
   * Non-visa queries bypass retrieval, reducing unnecessary latency (Zhang et al., 2024).

3. **Retriever**

   * Visa-related documents are embedded into vector representations using pre-trained models (Johnson, Douze, & Jégou, 2019).
   * A vector database performs similarity search, ensuring responses are grounded in official references.

4. **Generator**

   * Retrieved evidence is passed to a Large Language Model (LLM) via the OpenAI API.
   * The LLM generates conversational, context-grounded responses. The API was chosen for feasibility within budget and time constraints.

5. **Deployment Setup**

   * The prototype runs locally, with **ngrok** enabling secure, internet-accessible integration with Messenger.
   * This setup avoids costly cloud infrastructure while enabling realistic testing.

### Evaluation Methods

To assess performance, the study applies **system-level** and **user-level** metrics, consistent with chatbot and RAG evaluation practices (Ji et al., 2023; Tunstall et al., 2023).

1. **Binary Classifier**

   * Evaluated with **precision, recall, and accuracy** to measure filtering effectiveness.

2. **Retriever and Generator (RAG Evaluation)**

   * **RAGAS metrics** (Es et al., 2023): faithfulness, factual correctness, context recall, and context precision.
   * **Latency**: median and 95th percentile response times, following best practices (Gupta et al., 2024).

3. **User Evaluation**

   * **System Usability Scale (SUS)** (Brooke, 1996): 10-item standardized usability score (0–100).
   * **Satisfaction Survey**: Likert-scale and open-ended items capturing clarity, usefulness, and satisfaction.

Together, these measures determine whether the chatbot delivers **accuracy, efficiency, and usability**, and whether it meaningfully assists with Japan visa inquiries.
