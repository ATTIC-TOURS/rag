## 3.3 Data Collection

The dataset used in this study was sourced from multiple reliable references:

1. Official Embassy Documents – publicly available PDF guidelines and requirements from the Embassy of Japan in the Philippines.

2. Travel Agency Resources – information and procedural guides provided by accredited agencies.

3. Synthetic Data – additional user queries were generated using a large language model (LLM) for multiple purposes: (a) to train a binary classification model that determines whether a query is Japan visa–related or not, thereby reducing unnecessary retrieval processes and minimizing latency; (b) to expand the variety of queries used in evaluating the RAG pipeline; (c) to assess the retrieval component’s ability to return relevant information; and (d) to measure the quality and accuracy of responses produced by the generation component.

### Data Processing and Storage

To ensure efficient and reliable information retrieval, several preprocessing steps were applied before storing the documents and queries in the vector database.

- Preprocessing of Embassy PDF Documents: Each PDF was treated as a self-contained document containing a specific concept or set of visa requirements. The text was cleaned by removing stop words and irrelevant details not directly related to visa processing. The cleaned documents were then split into smaller chunks. The chunk size varied depending on two factors: (a) the overall length of the document and (b) the token capacity supported by the embedding model. This dynamic adjustment ensured that each chunk was both semantically meaningful and within the model’s processing limits. To further improve contextual coherence, an LLM was used to generate a concise contextual summary for each chunk before embedding, allowing the retriever to capture not only the text but also its intended meaning.

- Synthetic Queries: Additional user queries generated by an LLM were reviewed to ensure alignment with official requirements and to maintain realism. These synthetic queries expanded the dataset for both training and evaluation of the RAG pipeline.

- Document Selection Criteria: Only the latest Japan visa requirements, updated as of April 2025, were included. Outdated or redundant versions of documents were excluded to prevent misinformation.

- Binary Classification Dataset Preparation: For training the binary classifier, text was cleaned and tokenized, retaining only essential keywords to reduce noise and improve model accuracy. This allowed the classifier to efficiently distinguish between Japan visa–related and non–visa-related queries, thereby minimizing unnecessary retrieval and improving overall system latency.

This structured processing workflow ensured that the dataset stored in the vector database was accurate, relevant, and optimized for both retrieval efficiency and evaluation of the RAG pipeline.