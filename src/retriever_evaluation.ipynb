{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4434be8c",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7494ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from retriever import Retriever\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa221a",
   "metadata": {},
   "source": [
    "# üóÉÔ∏è Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917ae0f",
   "metadata": {},
   "source": [
    "## Precision@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "527e065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_per_query_at_k(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    str_query_id = \"query_id\"\n",
    "    str_relevant = \"relevant\"\n",
    "    str_precision_at_k = f\"Precision@{k}\"\n",
    "\n",
    "    df_topk = df[df[\"rank\"] <= k]\n",
    "\n",
    "    precision_per_query_at_k = (\n",
    "        df_topk.groupby(str_query_id)\n",
    "        .apply(lambda g: g[str_relevant].sum() / k)\n",
    "        .reset_index(name=str_precision_at_k)\n",
    "    )\n",
    "    return precision_per_query_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f420c316",
   "metadata": {},
   "source": [
    "## Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f56d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_per_query_at_k(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    str_query_id = \"query_id\"\n",
    "    str_rank = \"rank\"\n",
    "    str_relevant = \"relevant\"\n",
    "    str_recall_at_k = f\"Recall@{k}\"\n",
    "    str_retrieved_relevant = \"retrieved_relevant\"\n",
    "    str_total_relevant = \"total_relevant\"\n",
    "\n",
    "    total_relevant = (\n",
    "        df.groupby(str_query_id)[str_relevant]\n",
    "        .sum()\n",
    "        .reset_index(name=str_total_relevant)\n",
    "    )\n",
    "\n",
    "    df_topk = df[df[str_rank] <= k]\n",
    "\n",
    "    recall_per_query_at_k = (\n",
    "        df_topk.groupby(str_query_id)\n",
    "        .apply(lambda g: (g[str_relevant].sum()))\n",
    "        .reset_index(name=str_retrieved_relevant)\n",
    "        .merge(total_relevant, on=str_query_id)\n",
    "    )\n",
    "\n",
    "    recall_per_query_at_k[str_recall_at_k] = (\n",
    "        recall_per_query_at_k[str_retrieved_relevant]\n",
    "        / recall_per_query_at_k[str_total_relevant]\n",
    "    )\n",
    "\n",
    "    return recall_per_query_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31022fe",
   "metadata": {},
   "source": [
    "## F1@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f2ea453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_per_query_at_k(df: pd.DataFrame, k: int) -> pd.Series:\n",
    "    df = df.copy()\n",
    "\n",
    "    str_precision_at_k = f\"Precision@{k}\"\n",
    "    str_recall_at_k = f\"Recall@{k}\"\n",
    "\n",
    "    precision_per_query_at_k = get_precision_per_query_at_k(df, k)\n",
    "    recall_per_query_at_k = get_recall_per_query_at_k(df, k)\n",
    "\n",
    "    f1_per_query_at_k = (\n",
    "        2\n",
    "        * precision_per_query_at_k[str_precision_at_k]\n",
    "        * recall_per_query_at_k[str_recall_at_k]\n",
    "    ) / (\n",
    "        precision_per_query_at_k[str_precision_at_k]\n",
    "        + recall_per_query_at_k[str_recall_at_k]\n",
    "    )\n",
    "\n",
    "    return f1_per_query_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed65e30",
   "metadata": {},
   "source": [
    "## Retriever Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99d64df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retriever_at_k(df: pd.DataFrame, k: int) -> dict[str, float]:\n",
    "    df = df.copy()\n",
    "\n",
    "    precision_per_query_at_k = get_precision_per_query_at_k(df, k)\n",
    "    mean_precision_at_k = precision_per_query_at_k[f\"Precision@{k}\"].mean()\n",
    "\n",
    "    recall_per_query_at_k = get_recall_per_query_at_k(df, k)\n",
    "    mean_recall_at_k = recall_per_query_at_k[f\"Recall@{k}\"].mean()\n",
    "    \n",
    "    f1_per_query_at_k = get_f1_per_query_at_k(df, k)\n",
    "    mean_f1_at_k = f1_per_query_at_k.mean()\n",
    "\n",
    "    return {\n",
    "        f\"Mean Precision@{k}\": mean_precision_at_k,\n",
    "        f\"Mean Recall@{k}\": mean_recall_at_k,\n",
    "        f\"Mean F1@{k}\": mean_f1_at_k\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e28ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retriever(annotation_pools: pd.DataFrame, top_k: tuple[int]):\n",
    "    evaluations_at_k = []\n",
    "    for k in top_k:\n",
    "        evaluation_at_k = evaluate_retriever_at_k(annotation_pools, k)\n",
    "        evaluations_at_k.append(evaluation_at_k)\n",
    "    \n",
    "    evaluation = {}\n",
    "    for evaluation_at_k in evaluations_at_k:\n",
    "        for key, value in evaluation_at_k.items():\n",
    "            evaluation[key] = value\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd74309",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3dcc9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_pools = pd.read_csv('annotations/annotations_kenji_b4c33c4c.csv', comment=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d957ed18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Saan po pwede mag apply ng Japan Visa bukod sa...</td>\n",
       "      <td>1</td>\n",
       "      <td>ATTIC TOURS.pdf_chunk_0</td>\n",
       "      <td>ATTIC TOURS.pdf</td>\n",
       "      <td>ATTIC TOURS</td>\n",
       "      <td>ATTIC TOURS\\nSpecialized in Japan Visa Applica...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Saan po pwede mag apply ng Japan Visa bukod sa...</td>\n",
       "      <td>2</td>\n",
       "      <td>JAPAN VISA GENERAL INFO.pdf_chunk_2</td>\n",
       "      <td>JAPAN VISA GENERAL INFO.pdf</td>\n",
       "      <td>JAPAN VISA ‚Äì GENERAL INFORMATION</td>\n",
       "      <td>B. REQUIREMENTSÔºàDetails ‚Üí https://www.ph.emb-j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Saan po pwede mag apply ng Japan Visa bukod sa...</td>\n",
       "      <td>3</td>\n",
       "      <td>NIKKEI-JIN (JAPANESE DESCENDANT).pdf_chunk_6</td>\n",
       "      <td>NIKKEI-JIN (JAPANESE DESCENDANT).pdf</td>\n",
       "      <td>NIKKEI-JIN (JAPANESE DESCENDANT)</td>\n",
       "      <td>„ÄêIn case that applicant is planning to work fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                              query  rank  \\\n",
       "0         1  Saan po pwede mag apply ng Japan Visa bukod sa...     1   \n",
       "1         1  Saan po pwede mag apply ng Japan Visa bukod sa...     2   \n",
       "2         1  Saan po pwede mag apply ng Japan Visa bukod sa...     3   \n",
       "\n",
       "                                       chunk_id  \\\n",
       "0                       ATTIC TOURS.pdf_chunk_0   \n",
       "1           JAPAN VISA GENERAL INFO.pdf_chunk_2   \n",
       "2  NIKKEI-JIN (JAPANESE DESCENDANT).pdf_chunk_6   \n",
       "\n",
       "                              file_name                             title  \\\n",
       "0                       ATTIC TOURS.pdf                       ATTIC TOURS   \n",
       "1           JAPAN VISA GENERAL INFO.pdf  JAPAN VISA ‚Äì GENERAL INFORMATION   \n",
       "2  NIKKEI-JIN (JAPANESE DESCENDANT).pdf  NIKKEI-JIN (JAPANESE DESCENDANT)   \n",
       "\n",
       "                                             content  relevant  \n",
       "0  ATTIC TOURS\\nSpecialized in Japan Visa Applica...         1  \n",
       "1  B. REQUIREMENTSÔºàDetails ‚Üí https://www.ph.emb-j...         1  \n",
       "2  „ÄêIn case that applicant is planning to work fo...         0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bae1fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/4133079204.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[str_relevant].sum() / k)\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/1192718599.py:21: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (g[str_relevant].sum()))\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/4133079204.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[str_relevant].sum() / k)\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/1192718599.py:21: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (g[str_relevant].sum()))\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/4133079204.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[str_relevant].sum() / k)\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/1192718599.py:21: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (g[str_relevant].sum()))\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/4133079204.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[str_relevant].sum() / k)\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/1192718599.py:21: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (g[str_relevant].sum()))\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/4133079204.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[str_relevant].sum() / k)\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/1192718599.py:21: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (g[str_relevant].sum()))\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/4133079204.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g[str_relevant].sum() / k)\n",
      "/var/folders/0r/dktk9n0551j0gkccz4k6246h0000gn/T/ipykernel_1434/1192718599.py:21: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (g[str_relevant].sum()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Mean Precision@3': 0.6666666666666666,\n",
       " 'Mean Recall@3': 1.0,\n",
       " 'Mean F1@3': 0.8,\n",
       " 'Mean Precision@5': 0.4,\n",
       " 'Mean Recall@5': 1.0,\n",
       " 'Mean F1@5': 0.5714285714285715,\n",
       " 'Mean Precision@10': 0.2,\n",
       " 'Mean Recall@10': 1.0,\n",
       " 'Mean F1@10': 0.33333333333333337}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_retriever(annotated_pools, top_k = (3, 5, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
