{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5db4e0",
   "metadata": {},
   "source": [
    "# Chunking\n",
    "\n",
    "flow\n",
    "1. Retrieve PDFs\n",
    "2. Chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520fc35",
   "metadata": {},
   "source": [
    "## 1. Retrieve PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161801f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.11.1)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/krimssmirk/Desktop/rag/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "\n",
    "BASE_URL = \"https://www.ph.emb-japan.go.jp/itpr_en/00_000035.html\"\n",
    "output_dir = \"data/raw_pdfs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Mobile Safari/537.36\"}\n",
    "\n",
    "# Fetch the page\n",
    "response = requests.get(BASE_URL, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "# Find all PDF links\n",
    "pdf_links = [urljoin(BASE_URL, a['href']) \n",
    "             for a in soup.find_all(\"a\", href=True) if a['href'].endswith(\".pdf\")]\n",
    "\n",
    "print(f\"Found {len(pdf_links)} PDFs\")\n",
    "\n",
    "# Download each PDF\n",
    "for link in pdf_links:\n",
    "    filename = link.split(\"/\")[-1]\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    print(f\"Downloading {filename}\")\n",
    "    pdf_data = requests.get(link, headers=headers)\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        f.write(pdf_data.content)\n",
    "\n",
    "print(\"‚úÖ Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import os\n",
    "import json\n",
    "\n",
    "pdf_dir = \"data/raw_pdfs\"  # folder containing your PDFs\n",
    "pdf_file = os.listdir(pdf_dir)[0]\n",
    "print(pdf_file)\n",
    "print()\n",
    "\n",
    "pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "with pymupdf.open(pdf_path) as doc:\n",
    "    print(doc)\n",
    "    print(f'#page: {doc.page_count}')\n",
    "    print(f'metadata: {json.dumps(doc.metadata, indent=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "doc = pymupdf.open(pdf_path) # open a document\n",
    "for page in doc:\n",
    "    print(page.get_text())\n",
    "    # print(page.get_links())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1741a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c49974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "pdf_dir = \"data/raw_pdfs\"  # folder containing your PDFs\n",
    "\n",
    "# Loop through all PDFs\n",
    "for pdf_file in os.listdir(pdf_dir):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        \n",
    "        # Open PDF\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            # Try to read document metadata title first\n",
    "            title = doc.metadata.get(\"title\", \"\")\n",
    "            \n",
    "            if not title:\n",
    "                # Fallback: read the first page text and take the first line as title\n",
    "                first_page_text = doc[0].get_text(\"text\").strip()\n",
    "                title = first_page_text.split(\"\\n\")[0] if first_page_text else \"No title found\"\n",
    "            \n",
    "            print(f\"üìÑ {pdf_file} ‚Üí Title: {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e91af5f",
   "metadata": {},
   "source": [
    "## 2. Chunking (Section-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6505b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Processing: 100479463.pdf\n",
      "üìÑ Processing: 100365628.pdf\n",
      "üìÑ Processing: this-is-a-message-to-you-EN.pdf\n",
      "üìÑ Processing: 100508288.pdf\n",
      "üìÑ Processing: 100508289.pdf\n",
      "üìÑ Processing: 100325630.pdf\n",
      "üìÑ Processing: 100325631.pdf\n",
      "üìÑ Processing: 000308386.pdf\n",
      "üìÑ Processing: 100585068.pdf\n",
      "üìÑ Processing: 100401397.pdf\n",
      "üìÑ Processing: 100475176.pdf\n",
      "üìÑ Processing: 100415047.pdf\n",
      "üìÑ Processing: 100415046.pdf\n",
      "üìÑ Processing: 100662512.pdf\n",
      "üìÑ Processing: 100404404.pdf\n",
      "üìÑ Processing: 100415048.pdf\n",
      "üìÑ Processing: 100475146.pdf\n",
      "üìÑ Processing: 100365641.pdf\n",
      "üìÑ Processing: 100825869.pdf\n",
      "üìÑ Processing: 100585059.pdf\n",
      "üìÑ Processing: 100674192.pdf\n",
      "üìÑ Processing: 100480646.pdf\n",
      "üìÑ Processing: 100365634.pdf\n",
      "üìÑ Processing: 100325628.pdf\n",
      "üìÑ Processing: 100508287.pdf\n",
      "üìÑ Processing: 100365635.pdf\n",
      "üìÑ Processing: 100365623.pdf\n",
      "üìÑ Processing: 100401465.pdf\n",
      "üìÑ Processing: 100508284.pdf\n",
      "üìÑ Processing: 100508285.pdf\n",
      "üìÑ Processing: 100365636.pdf\n",
      "üìÑ Processing: 100365632.pdf\n",
      "üìÑ Processing: 100365626.pdf\n",
      "üìÑ Processing: 100324691.pdf\n",
      "üìÑ Processing: 100508281.pdf\n",
      "üìÑ Processing: 100365627.pdf\n",
      "üìÑ Processing: 100365633.pdf\n",
      "üìÑ Processing: 100365625.pdf\n",
      "üìÑ Processing: 100365631.pdf\n",
      "üìÑ Processing: 100508282.pdf\n",
      "üìÑ Processing: 100508283.pdf\n",
      "üìÑ Processing: 100324693.pdf\n",
      "‚úÖ Created 146 section-based chunks ‚Üí saved to pdf_chunks.json\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "pdf_dir = \"data/raw_pdfs\"\n",
    "output_file = \"pdf_chunks.json\"\n",
    "\n",
    "def section_based_chunking(text, max_items=10):\n",
    "    \"\"\"\n",
    "    Groups related lines into bigger chunks (max_items = how many requirement items to group).\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\r\", \"\\n\")\n",
    "    lines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    item_count = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        # Start of major heading (A. PURPOSE, B. REQUIREMENTS)\n",
    "        if re.match(r\"^[A-Z]\\.\\s\", line):\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = \"\"\n",
    "                item_count = 0\n",
    "            current_chunk = line\n",
    "        \n",
    "        # Numbered item (1), (2), (3)\n",
    "        elif re.match(r\"^\\(\\d+\\)\", line):\n",
    "            if item_count >= max_items:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = \"\"\n",
    "                item_count = 0\n",
    "            \n",
    "            current_chunk += \"\\n\" + line\n",
    "            item_count += 1\n",
    "        \n",
    "        # Special headings „ÄêADDITIONAL REQUIREMENTS„Äë\n",
    "        elif line.startswith(\"„Äê\") and line.endswith(\"„Äë\"):\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = \"\"\n",
    "                item_count = 0\n",
    "            current_chunk = line\n",
    "        \n",
    "        else:\n",
    "            # Add bullets, sub-text, or anything else\n",
    "            current_chunk += \"\\n\" + line\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "# Loop through PDFs\n",
    "for pdf_file in os.listdir(pdf_dir):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        print(f\"üìÑ Processing: {pdf_file}\")\n",
    "        \n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            title = doc.metadata.get(\"title\", \"\")\n",
    "            \n",
    "            text = \"\"\n",
    "            for page in doc:\n",
    "                text += page.get_text(\"text\") + \"\\n\"\n",
    "            \n",
    "            if not title and text.strip():\n",
    "                title = text.split(\"\\n\")[0]\n",
    "            \n",
    "            # Chunk with wider grouping\n",
    "            chunks = section_based_chunking(text, max_items=10)\n",
    "            \n",
    "            for idx, chunk in enumerate(chunks):\n",
    "                data.append({\n",
    "                    \"file_name\": pdf_file,\n",
    "                    \"title\": title.strip(),\n",
    "                    \"chunk_id\": f\"{pdf_file}_chunk_{idx}\",\n",
    "                    \"content\": chunk\n",
    "                })\n",
    "\n",
    "# Save JSON\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Created {len(data)} section-based chunks ‚Üí saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
